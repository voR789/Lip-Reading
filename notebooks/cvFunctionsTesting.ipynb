{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa435be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ngrid_vocab = {\\n    \"<pad>\": 0,\\n    \"<sos>\": 1,\\n    \"<eos>\": 2,\\n    \"sp\": 3,\\n    \"bin\": 4,\\n    \"lay\": 5,\\n    \"place\": 6,\\n    \"set\": 7,\\n    \"blue\": 8,\\n    \"green\": 9,\\n    \"red\": 10,\\n    \"white\": 11,\\n    \"at\": 12,\\n    \"by\": 13,\\n    \"in\": 14,\\n    \"with\": 15,\\n    \"zero\": 16,\\n    \"one\": 17,\\n    \"two\": 18,\\n    \"three\": 19,\\n    \"four\": 20,\\n    \"five\": 21,\\n    \"six\": 22,\\n    \"seven\": 23,\\n    \"eight\": 24,\\n    \"nine\": 25,\\n    \"again\": 26,\\n    \"now\": 27,\\n    \"please\": 28,\\n    \"soon\": 29,\\n    \"a\": 30,\\n    \"b\": 31,\\n    \"c\": 32,\\n    \"d\": 33,\\n    \"e\": 34,\\n    \"f\": 35,\\n    \"g\": 36,\\n    \"h\": 37,\\n    \"i\": 38,\\n    \"j\": 39,\\n    \"k\": 40,\\n    \"l\": 41,\\n    \"m\": 42,\\n    \"n\": 43,\\n    \"o\": 44,\\n    \"p\": 45,\\n    \"q\": 46,\\n    \"r\": 47,\\n    \"s\": 48,\\n    \"t\": 49,\\n    \"u\": 50,\\n    \"v\": 51,\\n    \"x\": 52,\\n    \"y\": 53,\\n    \"z\": 54\\n}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "grid_vocab = {\n",
    "    \"<pad>\": 0,\n",
    "    \"<sos>\": 1,\n",
    "    \"<eos>\": 2,\n",
    "    \"sp\": 3,\n",
    "    \"bin\": 4,\n",
    "    \"lay\": 5,\n",
    "    \"place\": 6,\n",
    "    \"set\": 7,\n",
    "    \"blue\": 8,\n",
    "    \"green\": 9,\n",
    "    \"red\": 10,\n",
    "    \"white\": 11,\n",
    "    \"at\": 12,\n",
    "    \"by\": 13,\n",
    "    \"in\": 14,\n",
    "    \"with\": 15,\n",
    "    \"zero\": 16,\n",
    "    \"one\": 17,\n",
    "    \"two\": 18,\n",
    "    \"three\": 19,\n",
    "    \"four\": 20,\n",
    "    \"five\": 21,\n",
    "    \"six\": 22,\n",
    "    \"seven\": 23,\n",
    "    \"eight\": 24,\n",
    "    \"nine\": 25,\n",
    "    \"again\": 26,\n",
    "    \"now\": 27,\n",
    "    \"please\": 28,\n",
    "    \"soon\": 29,\n",
    "    \"a\": 30,\n",
    "    \"b\": 31,\n",
    "    \"c\": 32,\n",
    "    \"d\": 33,\n",
    "    \"e\": 34,\n",
    "    \"f\": 35,\n",
    "    \"g\": 36,\n",
    "    \"h\": 37,\n",
    "    \"i\": 38,\n",
    "    \"j\": 39,\n",
    "    \"k\": 40,\n",
    "    \"l\": 41,\n",
    "    \"m\": 42,\n",
    "    \"n\": 43,\n",
    "    \"o\": 44,\n",
    "    \"p\": 45,\n",
    "    \"q\": 46,\n",
    "    \"r\": 47,\n",
    "    \"s\": 48,\n",
    "    \"t\": 49,\n",
    "    \"u\": 50,\n",
    "    \"v\": 51,\n",
    "    \"x\": 52,\n",
    "    \"y\": 53,\n",
    "    \"z\": 54\n",
    "}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6399b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.python.solutions.drawing_utils import draw_landmarks\n",
    "from mediapipe.python.solutions import drawing_styles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from util import mediapipe_utils\n",
    "from util import opencv_utils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(mediapipe_utils)\n",
    "importlib.reload(opencv_utils)\n",
    "\n",
    "from util.mediapipe_utils import *\n",
    "from util.opencv_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Daniel Path\n",
    "video_path = r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\GRID\\s1\\s1\\bbaf2n.mpg\"\n",
    "align_path = r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\GRID\\align_s1\\bbaf2n.align\"\n",
    "# Ryan Path\n",
    "# video_path = r\"C:\\Projects\\Lip_Reading\\GRID\\s1\\bbaf2n.mpg\"\n",
    "# align_path = r\"C:\\Projects\\Lip_Reading\\GRID\\align_s1\\bbaf2n.align\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0eae19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test proccessClip\n",
    "video = load_video(video_path)\n",
    "a,b,c = proccessClip(video)\n",
    "\n",
    "df1 = pd.DataFrame(a)\n",
    "df2 = pd.DataFrame(b)\n",
    "df3 = pd.DataFrame(c)\n",
    "\n",
    "\n",
    "\n",
    "# df1.to_csv(\"C:\\\\Projects\\\\Lip_Reading\\\\notebooks\\\\test_data\\\\engineered_features.csv\")\n",
    "# df2.to_csv(\"C:\\\\Projects\\\\Lip_Reading\\\\notebooks\\\\test_data\\\\landmark_coordinates.csv\")\n",
    "# df3.to_csv(\"C:\\\\Projects\\\\Lip_Reading\\\\notebooks\\\\test_data\\\\landmark_velocities.csv\")\n",
    "\n",
    "# df1.to_csv(r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\notebooks\\test_data\\engineered_features.csv\")\n",
    "# df2.to_csv(r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\notebooks\\test_data\\landmark_coordinates.csv\")\n",
    "# df3.to_csv(r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\notebooks\\test_data\\landmark_velocities.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1b36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = extractClips(align_path)\n",
    "for segment in segments:\n",
    "    clip = video[segment[0]:segment[1]]\n",
    "    a, b, c = proccessClip(clip)\n",
    "    \n",
    "    # display as csv\n",
    "    # df1 = pd.DataFrame(a)\n",
    "    # df1.to_csv(f\"C:\\\\Projects\\\\Lip_Reading\\\\notebooks\\\\test_data\\\\Engineered_Features_{segment[2]}.csv\")\n",
    "    # df2 = pd.DataFrame(b)\n",
    "    # df2.to_csv(f\"C:\\\\Projects\\\\Lip_Reading\\\\notebooks\\\\test_data\\\\Coordinates_{segment[2]}.csv\")\n",
    "    # df3 = pd.DataFrame(c)\n",
    "    # df3.to_csv(f\"C:\\\\Projects\\\\Lip_Reading\\\\notebooks\\\\test_data\\\\Velocities_{segment[2]}.csv\")\n",
    "\n",
    "    # Daniel's path\n",
    "    df1 = pd.DataFrame(a)\n",
    "    df1.to_csv(f\"C:\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\Projects\\\\Lip-Reading\\\\notebooks\\\\test_data\\\\Engineered_Features_{segment[2]}.csv\")\n",
    "    df2 = pd.DataFrame(b)\n",
    "    df2.to_csv(f\"C:\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\Projects\\\\Lip-Reading\\\\notebooks\\\\test_data\\\\Coordinates_{segment[2]}.csv\")\n",
    "    df3 = pd.DataFrame(c)\n",
    "    df3.to_csv(f\"C:\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\Projects\\\\Lip-Reading\\\\notebooks\\\\test_data\\\\Velocities_{segment[2]}.csv\")\n",
    "    \n",
    "    # to np array\n",
    "    # print(toArray(a))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
