{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1806e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.python.solutions.drawing_utils import draw_landmarks\n",
    "from mediapipe.python.solutions import drawing_styles\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from util import mediapipe_utils\n",
    "from util import opencv_utils\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "\n",
    "importlib.reload(mediapipe_utils)\n",
    "importlib.reload(opencv_utils)\n",
    "\n",
    "from util.mediapipe_utils import *\n",
    "from util.opencv_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Extract and display first frame\n",
    "# Daniel Path\n",
    "video_path = r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\GRID\\s1\\s1\\bbaf2n.mpg\"\n",
    "# Ryan Path\n",
    "# video_path = r\"C:\\Projects\\Lip_Reading\\GRID\\s1\\bbaf2n.mpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f47b0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate lip landmarks and coordinates\n",
    "# Outer lips (full loop)\n",
    "outer_lips = [\n",
    "    61, 146, 91, 181, 84, 17,\n",
    "    314, 405, 321, 375, 291, 409, \n",
    "    270, 269, 267, 0, 37, 39, 40, 185\n",
    "]\n",
    "\n",
    "# Inner lips (inside mouth opening)\n",
    "inner_lips = [\n",
    "    78, 95, 88, 178, 87, \n",
    "    14, 317, 402, 318, 324, \n",
    "    308, 415, 310, 311, 312, \n",
    "    13, 82, 81, 80, 191\n",
    "]\n",
    "\n",
    "inner_mouth = [\n",
    "    184, 183, 74, 42, 73, 41, 72, 38,\n",
    "    11, 12, 302, 268, 303, 271, 304, 272,408,\n",
    "    407, 96, 77, 89, 90, 179, 180, 86, 85, 15, \n",
    "    16, 316, 315, 403, 404, 319, 320, 325, 307\n",
    "]\n",
    "\n",
    "lower_jaw = [\n",
    "    148, 152, 377\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4de6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_landmarks(video_path, frame_number):\n",
    "    # Crop and proccess landmarks\n",
    "    frame = load_video(video_path)[frame_number]\n",
    "    landmarks = get_landmarks(frame)[0] # 0 being the first face found\n",
    "    coords = convert_landmarks_to_coordinates(landmarks, frame.shape)\n",
    "    x_min, y_min, x_max, y_max = get_bounding_box(coords, frame.shape)\n",
    "    cropped_frame = frame[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "    \n",
    "    cropped_landmarks = get_landmarks(cropped_frame)[0]\n",
    "    h, w, _ = cropped_frame.shape\n",
    "    coords = convert_landmarks_to_coordinates(cropped_landmarks, (h, w))\n",
    "    \n",
    "    return (cropped_landmarks, coords, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2acd2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Features\n",
    "# Divide by dimensions of cropped face to account for face sizes \n",
    "# Use face height and eye distance as normailization metrics\n",
    "    \n",
    "def normalize_vertical_measurements(coords, measurements):\n",
    "    face_height = landmark_dist(coords[10], coords[152])\n",
    "    return [m/face_height for m in measurements]\n",
    "\n",
    "def normalize_horizontal_measurements(coords, measurements):\n",
    "    eye_dist = landmark_dist(coords[133], coords[362])\n",
    "    return [m/eye_dist for m in measurements]\n",
    "\n",
    "def normalize_area(coords, measurements):\n",
    "    face_height = landmark_dist(coords[10], coords[152])\n",
    "    eye_dist = landmark_dist(coords[133], coords[362])\n",
    "    return [m/(face_height*eye_dist) for m in measurements]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4acd328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_measurements(video_path, frame_number):\n",
    "\n",
    "    landmarks, coords, h, w = setup_landmarks(video_path, frame_number)\n",
    "\n",
    "    upper_vermillion_height = landmark_dist(coords[13], coords[0])\n",
    "    lower_verillion_height = landmark_dist(coords[14], coords[17])\n",
    "\n",
    "    vert_distance = landmark_dist(coords[13], coords[14])\n",
    "    hori_distance = landmark_dist(coords[308], coords[78])\n",
    "    aspect_ratio = hori_distance/vert_distance\n",
    "\n",
    "    lower_jaw_distance = landmark_dist(coords[14], coords[152])\n",
    "\n",
    "    inner_mouth_area = abs(area_of_points(inner_lips, coords))\n",
    "    outer_mouth_area = abs(area_of_points(outer_lips, coords))\n",
    "\n",
    "    norm_uvh, norm_lvh, norm_vd, norm_jd = normalize_vertical_measurements(coords, [upper_vermillion_height,lower_verillion_height,vert_distance,lower_jaw_distance])\n",
    "    norm_hd = normalize_horizontal_measurements(coords, [hori_distance])\n",
    "    norm_ar = norm_hd/norm_vd\n",
    "    norm_ima, norm_oma = normalize_area(coords, [inner_mouth_area, outer_mouth_area])\n",
    "\n",
    "    return [\n",
    "        upper_vermillion_height,\n",
    "        lower_verillion_height,\n",
    "        vert_distance,\n",
    "        hori_distance,\n",
    "        aspect_ratio,\n",
    "        lower_jaw_distance,\n",
    "        inner_mouth_area,\n",
    "        outer_mouth_area,\n",
    "        norm_uvh,\n",
    "        norm_lvh,\n",
    "        norm_vd,\n",
    "        norm_hd,\n",
    "        norm_ar,\n",
    "        norm_jd,\n",
    "        norm_ima,\n",
    "        norm_oma\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "104d751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Avgeraged Measurements\n",
    "# Average over 3 frames to get a more stable measurement\n",
    "\n",
    "# [upper_vermillion_height, lower_vermillion_height, vert_distance, hori_distance, aspect_ratio, lower_jaw_distance, inner_mouth_area, outer_mouth_area]\n",
    "# [norm_uvh, norm_lvh, norm_vd, norm_hd, norm_ar, norm_jd, norm_ima, norm_oma]\n",
    "def get_average_resting(video_path):\n",
    "    avg_features = []\n",
    "    for i in range(3): # Average of first three frames\n",
    "        vals = get_primary_measurements(video_path,i)\n",
    "        for j in range(16):\n",
    "            avg_features += vals[j]\n",
    "    avg_features = [x / 3 for x in avg_features]\n",
    "    return avg_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41e9ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_measurement(video_path, frame_number, data_table , average_resting_vals):    \n",
    "    # Primary measurements\n",
    "    upper_vermillion_height,lower_verillion_height,vert_distance,hori_distance,aspect_ratio,lower_jaw_distance,inner_mouth_area,outer_mouth_area,norm_uvh,norm_lvh,norm_vd,norm_hd,norm_ar,norm_jd,norm_ima,norm_oma = get_primary_measurements(video_path, frame_number)\n",
    "\n",
    "    landmarks, coords, h, w = setup_landmarks(video_path, frame_number)\n",
    "    \n",
    "    # Temporal landmarks and scientific - engineered landmarks\n",
    "\n",
    "        # Vertical Lip Compression\n",
    "        # - Measures how \"pursed\" the lips are\n",
    "        \n",
    "        # Corner Displacement\n",
    "        # - Measures how tightened mouth is\n",
    "        \n",
    "        # Key Landmark Velocities \n",
    "        # - Track velocity of key landmarks using x2-x1 / t2-t1, such as lip corners, top and bottom of inner edge of lip, etc.\n",
    "\n",
    "    if(frame_number == 0): # grab average resting values from begining of video\n",
    "        average_resting_vals = get_average_resting(video_path)\n",
    "\n",
    "    vert_lip_compression = (upper_vermillion_height + lower_verillion_height) / (average_resting_vals[0] + average_resting_vals[1])\n",
    "    corner_displacement = hori_distance / average_resting_vals[3]\n",
    "    \n",
    "    norm_vlc = normalize_vertical_measurements(coords, [vert_lip_compression])\n",
    "    norm_cd = normalize_horizontal_measurements(coords, [corner_displacement])\n",
    "    \n",
    "    if frame_number == 0:\n",
    "        lip_corner_velocity = 0\n",
    "        top_inner_lip_velocity = 0\n",
    "        bottom_inner_lip_velocity = 0\n",
    "    else:\n",
    "        lip_corner_velocity = hori_distance - data_table[frame_number - 1][3] \n",
    "        top_inner_lip_velocity = upper_vermillion_height - data_table[frame_number - 1][0]\n",
    "        bottom_inner_lip_velocity = lower_verillion_height - data_table[frame_number - 1][1]\n",
    "    \n",
    "    return([\n",
    "        frame_number,\n",
    "        float(upper_vermillion_height),\n",
    "        float(lower_verillion_height),\n",
    "        float(vert_distance),\n",
    "        float(hori_distance),\n",
    "        float(aspect_ratio),\n",
    "        float(lower_jaw_distance),\n",
    "        float(inner_mouth_area),\n",
    "        float(outer_mouth_area),\n",
    "        float(norm_uvh),\n",
    "        float(norm_lvh),\n",
    "        float(norm_vd),\n",
    "        float(norm_hd),\n",
    "        float(norm_ar),\n",
    "        float(norm_jd),\n",
    "        float(norm_ima),\n",
    "        float(norm_oma),\n",
    "        float(norm_vlc),\n",
    "        float(norm_cd),\n",
    "        float(vert_lip_compression),\n",
    "        float(norm_vlc),\n",
    "        float(corner_displacement),\n",
    "        float(norm_cd),\n",
    "        float(lip_corner_velocity),\n",
    "        float(top_inner_lip_velocity),\n",
    "        float(bottom_inner_lip_velocity)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46fa463b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m average_resting_vals \u001b[38;5;241m=\u001b[39m get_average_resting(video_path)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_frames):\n\u001b[1;32m----> 9\u001b[0m     frame_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_frame_measurement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_resting_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurements_2D_arr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeasurements_2D_arr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[56], line 21\u001b[0m, in \u001b[0;36mget_frame_measurement\u001b[1;34m(video_path, frame_number, data_table, average_resting_vals)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(frame_number \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m): \u001b[38;5;66;03m# grab average resting values from begining of video\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     average_resting_vals \u001b[38;5;241m=\u001b[39m get_average_resting(video_path)\n\u001b[1;32m---> 21\u001b[0m vert_lip_compression \u001b[38;5;241m=\u001b[39m (upper_vermillion_height \u001b[38;5;241m+\u001b[39m lower_verillion_height) \u001b[38;5;241m/\u001b[39m (\u001b[43maverage_resting_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m average_resting_vals[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     22\u001b[0m corner_displacement \u001b[38;5;241m=\u001b[39m hori_distance \u001b[38;5;241m/\u001b[39m average_resting_vals[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     24\u001b[0m norm_vlc \u001b[38;5;241m=\u001b[39m normalize_vertical_measurements(coords, [vert_lip_compression])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Make 2D array of measurements\n",
    "# Each row is a frame, each column is a measurement\n",
    "video_path = r\"C:\\Users\\User\\OneDrive\\Documents\\Projects\\Lip-Reading\\GRID\\s1\\s1\\bbaf2n.mpg\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "data_table = [[]]\n",
    "average_resting_vals = get_average_resting(video_path)\n",
    "for i in range(total_frames):\n",
    "    frame_data = get_frame_measurement(video_path,i,data_table, average_resting_vals)\n",
    "    print(f\"Frame {i}: {frame_data}\")\n",
    "    print(f\"measurements_2D_arr: {measurements_2D_arr}\")\n",
    "    measurements_2D_arr[i].append(frame_data)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
